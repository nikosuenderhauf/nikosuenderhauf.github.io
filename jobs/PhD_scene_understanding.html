<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Niko Sünderhauf | PhD Topic – Geometric-Semantic Representations for Scene Understanding</title>
  <meta name="description" content="">

  <link rel="shortcut icon" href="https://nikosuenderhauf.github.io/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/main.css">
  <link rel="canonical" href="https://nikosuenderhauf.github.io/jobs/PhD_scene_understanding">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Niko</strong> Sünderhauf
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://nikosuenderhauf.github.io/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="https://nikosuenderhauf.github.io/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/cv/">bio</a>
          
        
          
        
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/projects/">research</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/publications/">publications</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/teaching/">teaching</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/jobs/">recruiting</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/workshops/">workshops</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://nikosuenderhauf.github.io/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">PhD Topic – Geometric-Semantic Representations for Scene Understanding</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content PhD Topic – Geometric-Semantic Representations for Scene Understanding clearfix">
    <p>Making a robot understand what it sees is one of the most fascinating goals in our current research.</p>

<p>In this project, you develop novel methods for Semantic Mapping and Semantic SLAM by combining object detection with simultaneous localisation and mapping (SLAM) techniques.</p>

<p>We work on novel approaches to SLAM that create semantically meaningful maps by combining geometric and semantic information. Such semantically enriched maps will help robots understand our complex world and will ultimately increase the range and sophistication of interactions that robots can have in domestic and industrial deployment scenarios.</p>

<p>If you are interested in tightly combining modern deep learning and computer vision approaches with classical probabilistic robotics, this topic is for you. Our PhD topics give you the opportunity to investigate how to use recent implicit representations (such as NERFs) to represent scenes and objects, and how to use such scene representations for navigation but also for robotic learning for mobile manipulation.</p>

<p>Have a look at <a href="../projects/sceneunderstanding">similar research</a> I have been doing with my students, postdocs and colleagues.</p>

<h3 id="apply-now-for-your-phd-with-me-in-2025">Apply now for your PhD with me in 2025!</h3>
<p>To work with me on one of the topics below, you have to apply for a scholarship through <a href="https://www.qut.edu.au/research/study-with-us/how-to-apply">QUT’s scholarship round</a>. 
If you are successful in obtaining a scholarship, you can start your PhD between January and June 2025.</p>

<p><strong>Application deadlines</strong></p>
<ul>
  <li>for international (i.e. non-Australian) students: 31 July 2024</li>
  <li>for domestic (i.e. Australian) students: 31 August 2024</li>
</ul>

<h3 id="join-the-team">Join the Team!</h3>
<p>As a PhD student, you would work closely with my wonderful current postdocs and students, e.g. <a href="https://krishanrana.github.io/">Dr Krishan Rana</a>, <a href="https://jhavl.com/">Dr Jesse Haviland</a> or <a href="https://jadchakra.github.io/">Jad Abou-Chakra</a>. You would of course also be embedded in the vibrant <a href="http://qcr.ai">QUT Centre for Robotics</a> and get a chance to collaborate with any of the 100+ researchers in our group.</p>

<h3 id="about-the-position">About the Position</h3>
<p><img class="col one" src="/assets/img/jobs/campus-1.jpg" />
I am looking for a creative and enthusiastic PhD researcher to contribute to the Visual Learning and Understanding research program. You will be a member of the QUT Centre for Robotics and will work closely with academics, research fellows, engineers, and other PhD students.</p>

<p><strong>You should be excited to do pioneering research in Robotic Learning and Robotic Scene Understanding</strong></p>

<ul>
  <li>Scholarship: $32,500 AUD per year, tax free (via a competitive application process)</li>
  <li>$5,000 top-up scholarship available</li>
  <li>multiple positions available</li>
  <li>start date: immediately and ongoing</li>
</ul>

<h3 id="how-to-apply">How to Apply</h3>

<p>First, you should <a href="https://www.qut.edu.au/research/study-with-us/how-to-apply">check that you are eligible</a> to do a PhD at QUT. Then, <a href="https://www.qut.edu.au/about/our-people/academic-profiles/niko.suenderhauf">contact me via email</a> and include:</p>
<ul>
  <li>your CV, including academic transcript</li>
  <li>a description of your research interests, describing the topic you are interested in, and why</li>
  <li>a short summary about a previous research experience you are most proud of</li>
</ul>

<p>I will be in touch if I think you would be a good fit for this project and for our lab.</p>

<h3 id="about-us">About Us</h3>
<p><img class="col one" src="/assets/img/jobs/S11-4.jpg" />
The QUT Centre for Robotics (QCR) conducts at-scale world-leading research in intelligent robotics; translates fundamental research into commercial and societal outcomes; is a leader in education, training and development of talent to meet growing demands for expertise in robotics and autonomous systems; and provides leadership in technological policy development and societal debate. Established in 2020, the Centre has been built on the momentum of a decade’s investment in robotic research and translation at QUT which has been funded by QUT, ARC, Queensland Government, CRCs and Industry. QCR comprises over 100 researchers and engineers.</p>

<p>QCR researchers collaborate with industry and universities around the world, including MIT, Harvard and Oxford universities, Boeing, Thales, DST, Airservices Australia, CASA, JARUS, TRAFI, Google Deepmind, Google AI, Amazon Robotics, Caterpillar, Rheinmetall, US Air Force, and NASA’s Jet Propulsion Laboratory.</p>

<p>We are proud of our beautiful and big modern lab space and research environment. We have a fantastic collection of equipment to support your research, including many mobile robot platforms and robotic arms.</p>

<p>The Centre supports a flexible working environment. We support a diverse and inclusive atmosphere and encourage applications from women, Aboriginal Australians and Torres Strait Islander people.</p>

<div class="img_row">
<img class="col one" src="/assets/img/jobs/S11-1.jpg" />
<img class="col one" src="/assets/img/jobs/S11-3.jpg" />
<img class="col one" src="/assets/img/jobs/S11-2.jpg" />
</div>

<h3 id="location">Location</h3>
<p>Queensland University of Technology (QUT), Gardens Point campus, Brisbane, Australia.
We are located on a beautiful campus next to the Brisbane City Botanic Gardens, just a few minutes on foot from the Brisbane CBD and the bustling Southbank cultural precinct with many fantastic restaurants and bars. QUT has excellent connections to public transport, including our CityCat river ferry, trains, and bus lines. A bike path along the river connects QUT with the nearby suburbs.</p>

<p>Brisbane is a very liveable sub-tropical city of 2.3M people and offers great opportunities for recreational activities ranging from hiking in the many nearby national parks, rock climbing (the Kangaroo Point crag is just across the river, and there are many of well-maintained sport crags in a 1-2 hour radius around Brisbane, as well as a selection of climbing and bouldering gyms in the city), surfing (the famous Gold Coast is just over one hour away), and all things beach and ocean related.</p>

<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m12!1m3!1d2906.049913465745!2d153.02894556592284!3d-27.47748600138352!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!5e1!3m2!1sen!2sau!4v1583472988458!5m2!1sen!2sau" width="600" height="450" frameborder="0" style="border:0;" allowfullscreen=""></iframe>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2025 Niko Sünderhauf.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://nikosuenderhauf.github.io/assets/js/common.js"></script>


<!-- Load KaTeX -->
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://nikosuenderhauf.github.io/assets/js/katex.js"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>






<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-135749210-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
