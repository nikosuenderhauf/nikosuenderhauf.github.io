<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Niko Sünderhauf | workshops</title>
  <meta name="description" content="">

  <link rel="shortcut icon" href="https://nikosuenderhauf.github.io/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/main.css">
  <link rel="canonical" href="https://nikosuenderhauf.github.io/workshops/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Niko</strong> Sünderhauf
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://nikosuenderhauf.github.io/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="https://nikosuenderhauf.github.io/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/cv/">bio</a>
          
        
          
        
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/projects/">research</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/publications/">publications</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/teaching/">teaching</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/jobs/">recruiting</a>
          
        
          
            <a class="page-link" href="https://nikosuenderhauf.github.io/workshops/">workshops</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://nikosuenderhauf.github.io/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">workshops</h1>
    <h5 class="post-description">Workshops I organised and co-organised.</h5>
  </header>

  <article class="post-content workshops clearfix">
    <p>I am very active in organising workshops at robotics and computer vision conferences.</p>

<hr />

<p><a href="https://sites.google.com/view/rlbp-icra2022/home"><strong>Behaviour Priors in Reinforcement Learning for Robotics</strong></a> (<strong>ICRA 2022</strong>)
The goal of this workshop was to discuss the role that behaviour priors could play in Reinforcement Learning for robotics. This includes the various ways in which we can learn/model these priors, methods to integrate their experience within the RL framework and their applicability to solving some of the key challenges faced by RL for real-world robotics.</p>

<hr />

<p><a href="https://embodied-ai.org/cvpr2022"><strong>Embodied AI Workshop</strong></a> (<strong>CVPR 2022</strong>)
Similar to the 2021 edition of the worksop, the goal of this workshop was to share and discuss the current state of intelligent agents that can: see,talk, listen, act, and reason. The Embodied AI 2021 workshop was held virtually in conjunction with CVPR 2021. It featured a host of invited talks covering a variety of topics in Embodied AI, many exciting challenges, a poster session, and panel discussions. We contributed the <a href="http://cvpr2022.roboticvisionchallenge.org/">Robotic Vision Scene Understanding Challenge</a></p>

<hr />

<p><a href="https://embodied-ai.org/cvpr2021"><strong>Embodied AI Workshop</strong></a> (<strong>CVPR 2021</strong>)
The goal of this workshop was to share and discuss the current state of intelligent agents that can: see,talk, listen, act, and reason. The Embodied AI 2021 workshop was held virtually in conjunction with CVPR 2021. It featured a host of invited talks covering a variety of topics in Embodied AI, many exciting challenges, a poster session, and panel discussions. We contributed the <a href="http://cvpr2021.roboticvisionchallenge.org/">Robotic Vision Scene Understanding Challenge</a></p>

<hr />

<p><a href="https://sites.google.com/view/rss20-gcr"><strong>Good Citizens of Robotics Research</strong></a> (<strong>RSS 2020</strong>)
This workshop provided a forum for discussions and commentary on topics about research, dissemination, and community, by taking inspiration from Computer Vision research and <a href="https://www.cc.gatech.edu/~parikh/citizenofcvpr/">this excellent CVPR workshop</a>. We discussed important questions like: How to incentivize and do good systems research? How to best disseminate results, code, and hardware? How to be a fair reviewer? How to be a good area chair? How to support a caring and inclusive community? How to bridge the gap between academia and industry and the role of ethics in their interplay? and in general how to go about being a good citizen of robotics research.</p>

<hr />

<p><a href="https://nikosuenderhauf.github.io/roboticvisionchallenges/eccv2020.html"><strong>Beyond mAP: Reassessing the Evaluation of Object Detectors</strong></a>  (<strong>ECCV 2020</strong>)
This workshop assessed current evaluation procedures for object detection, highlights their shortcomings and opens discussion for possible improvements.</p>

<hr />

<p><a href="https://sites.google.com/view/icra2020ltaws/"><strong>Reliable Deployment of Machine Learning for Long-Term Autonomy</strong></a> (<strong>IROS 2020</strong>)
This workshop focused on the problem of long-term autonomy for mobile robots and the challenge of building a reliabile machine learning components in the robotic system that can handle bad sensory data, shifts to abnormal operational conditions, misclassification and detections.</p>

<hr />

<p><a href="https://nikosuenderhauf.github.io/roboticvisionchallenges/iros2019"><strong>The Importance of Uncertainty in Deep Learning for Robotics</strong></a> (<strong>IROS 2019</strong>)</p>

<p>In this workshop we discussed the importance of uncertainty in deep learning for robotic applications. The workshop will provided tutorial-style talks that coverd the state-of-the-art of uncertainty quantification in deep learning, specifically Bayesian and non-Bayesian approaches, spanning perception, world-modeling, decision making, and actions. Invited expert speakers discussed the importance of uncertainty in deep learning for robotic perception, but also action.</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2019-iros.jpg" />
</div>

<hr />

<p><a href="https://nikosuenderhauf.github.io/roboticvisionchallenges/cvpr2019"><strong>Robotic Vision Probabilistic Object Detection Challenge</strong></a> (<strong>CVPR 2019</strong>)</p>

<p>This workshop brought together the participants of the first Robotic Vision Challenge on <a href="http://www.roboticvisionchallenge.org">Probabilistic Object Detection</a>, a new competition targeting both the computer vision and robotics communities. The workshop focussed on outcomes of the competition in the morning session, featuring talks by the four best scoring teams. After that we welcomed our invited speakers in the afternoon. Organised with Feras Dayoub and other colleagues from the Australian Centre for Robotic Vision, and Anelia Angelova from Google AI.</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2019-cvpr-probabilistic.jpg" />
</div>
<hr />

<p><a href="https://sites.google.com/view/sem-vis-nav"><strong>Deep Learning for Semantic Visual Navigation</strong></a> (<strong>CVPR 2019</strong>)</p>

<p>We discussed ideas to advance visual navigation by combining recent developments in deep and reinforcement learning. A special focus was on approaches that incorporate more semantic information into navigation, and combine visual input with other modalities such as language. Organised with colleagues from Google AI (Alexander Toshav, Anelia Angelova) and Imperial College London (Ronald Clark, Andrew Davison).</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2019-cvpr-semnav.jpg" />
</div>

<hr />

<p><a href="https://sites.google.com/view/rss2018-robotic-learning/home"><strong>New Benchmarks, Metrics, and Competitions for Robotic Learning</strong></a> (<strong>RSS 2018</strong>)</p>

<p>Similar in scope and topic to the CVPR workshop, here we discussed new benchmarks, competitions, and performance metrics that address the specific challenges arising when deploying (deep) learning in robotics.</p>

<hr />

<p><a href="https://sites.google.com/view/cvpr2018-robotic-vision"><strong>Real-World Challenges and New Benchmarks for Deep Learning in Robotic Vision</strong></a> (<strong>CVPR 2018</strong>)</p>

<p>In this workshop we discussed crucial challenges arising when deploying deep learning methods in real-world robotic applications, and a set of future large scale robotic vision benchmarks to address the critical challenges for robotic perception that are not yet covered by existing computer vision and robotics benchmarks, such as performance in open-set conditions, incremental learning with low-shot techniques, Bayesian optimisation, active learning, and active vision.</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2018-cvpr.jpg" />
</div>

<hr />

<p><a href="http://longtermautonomy.eu/"><strong>Long-term autonomy and deployment of intelligent robots in the real-world</strong></a> (<strong>ICRA 2018</strong>)</p>

<p>This workshop (led by <a href="http://www.google.com/url?q=http%3A%2F%2Fstaff.qut.edu.au%2Fstaff%2Fdayoub%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE-tlKEvYVgIqZ5312cYTJILFal0g">Feras Dayoub</a>) discussed the challenges of autonomous robots that have to reliably operate for long  periods of time while having to demonstrate a high level of robustness and fault tolerance.</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/ICRA18.JPG" />
</div>
<div class="col three caption">
    Our workshop at ICRA 2018 during the invited talk of John Leonard (MIT).
</div>

<hr />
<p><a href="https://sites.google.com/site/learningforslam/home"><strong>Learning for Localization and Mapping</strong></a> (IROS 2017)</p>

<p>The goal of this workshop was to present and discuss developments in learning-based approaches for localization and mapping systems.</p>

<p>Invited speakers: Wolfram Burgard (University of Freiburg), Jana Kosecka (George Mason University), Stefan Leutenegger (Imperial College London), Simon Lynen (Google), Marc Pollefeys (Microsoft).</p>

<p>Organised with
Cesar Cadena and Igor Gilitschenski (both ETH Zurich), John Leonard and Sudeep Pillai (both MIT), and Fabio Ramos (University of Sydney)</p>

<hr />
<p><a href="http://juxi.net/workshop/deep-learning-rss-2017/"><strong>New Frontiers for Deep Learning in Robotics</strong></a> (RSS 2017)</p>

<p>A wide range of renowned experts discussed deep learning techniques at the frontier of research that are not yet widely adopted, discussed, or well-known in our community. We carefully selected research topics such as Bayesian deep learning, generative models, or deep reinforcement learning for planning and navigation that are of high relevance and potentially groundbreaking for robotic perception, learning, and control. The workshop introduces these techniques to the robotics audience, but also exposes participants from the machine learning community to real-world problems encountered by robotics researchers that apply deep learning in their research.</p>

<p>Invited speakers: Yann LeCun (Facebook, NYU),  Yarin Gal (University of Cambridge), Josh Tenenbaum (MIT), David Cox (Harvard), Chelsea Finn (UC Berkeley), Piotr Mirowski (DeepMind), Aaron Courville (Université de Montréal).</p>

<p>Organised with the support of Jürgen Leitner, Michael Milford, Peter Corke (QUT, Brisbane), and Pieter Abbeel (UC Berkeley).</p>

<div class="img_row_large">
<img class="col half" src="/assets/img/workshops/2017-rss-speakers.jpg" />
<img class="col half" src="/assets/img/workshops/2017-rss-panel.jpg" />
</div>
<div class="col three caption">
    Invited speakers at our workshops at RSS in 2017.
</div>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2017-rss-Yann.jpg" />
</div>
<div class="col three caption">
    The audience during Yann LeCun's invited talk.
</div>
<hr />

<p><a href="http://juxi.net/workshop/deep-learning-robotic-vision-cvpr-2017/"><strong>Deep Learning for Robotic Vision</strong></a> (CVPR 2017)</p>

<p>Recent advances in deep learning techniques have made impressive progress in many areas of computer vision, including classification, detection, and segmentation. While all of these areas are relevant to robotics applications, robotics also presents many unique challenges which require new approaches.</p>

<p>Robotic vision specific challenges include the need for real-time analysis, the need for accurate 3d understanding of scenes, and the difficulty of doing experiments at scale. There are also opportunities robotics brings to computer vision, for example the ability to control position and viewing direction of the camera, and to provide a data source for “grounded” learning of concepts, reducing the need for manual labeling.</p>

<p>Invited speakers: Jitendra Malik (UC Berkeley), Raquel Urtasun (U Toronto / Uber ATG), Dieter Fox (U Washington), Honglak Lee (Google Brain / U Michigan), Abhinav Gupta (CMU), Jianxiong Xiao (AutoX), Richard Newcombe (Facebook), Raia Hadsell (Google DeepMind), Ashutosh Saxena (Brain of Things).</p>

<p>Organised with support from Jürgen Leitner, Michael Milford, Ben Upcroft, Peter Corke (QUT, Brisbane), Pieter Abbeel (UC Berkeley), Wolfram Burgard (Uni Freiburg).</p>

<div class="img_row_large">
<img class="col two" src="/assets/img/workshops/2017-cvpr-speakers.jpg" />
</div>
<div class="col two caption">
    Invited speakers at our workshops at CVPR in 2017.
</div>

<hr />

<p><a href="http://juxi.net/workshop/deep-learning-rss-2016/"><strong>Are the Sceptics Right? - Limits and Potentials of Deep Learning in Robotics</strong></a> (RSS 2016)</p>

<p>We analysed why deep learning has not yet had the huge impact in robotics it had in neighboring research disciplines, and especially in computer vision. The workshop will identify the limits and potentials of current deep learning techniques in robotics, and will propose directions for future research to overcome those limits and realize the promising potentials.</p>

<p>Invited speakers: John Leonard (MIT), Larry Jackel (North C Technologies), Dieter Fox (Washington University), Oliver Brock (TU Berlin), Pieter Abbeel (UC Berkeley), Walter Scheirer (University of Notre Dame), Raia Hadsell (Google DeepMind), Ashutosh Saxena (Cornell and Stanford University).</p>

<p>Co-organisers were Jürgen Leitner, Michael Milford, Ben Upcroft, Peter Corke (QUT, Brisbane), Pieter Abbeel (UC Berkeley), Wolfram Burgard (Uni Freiburg).</p>

<div class="img_row">
<img class="col three" src="/assets/img/workshops/2016-rss-audience.jpg" />
</div>
<div class="col three caption">
    Our workshop was the best attended of RSS 2016.
</div>
<hr />

<p><a href="http://tinyurl.com/vprice-RSS16"><strong>Visual Place Recognition: What is it good for?</strong></a> (RSS 2016)</p>

<p>This half-day workshop, co-organised with Ben Upcroft, Michael Milford (QUT, Brisbane), and Peer Neubert (TU Chemnitz), focussed on concepts and ideas for robust vision‐based place recognition in severely changing environments as well as discussing the extent to which place recognition is useful, or even required for robots.</p>

<hr />
<p><a href="http://www.tinyurl.com/vprice-ICRA15"><strong>Visual Place Recognition in Changing Environments</strong></a> (ICRA 2015)</p>

<p>This half-day workshop at ICRA 2015 in Seattle built on the highly successful 2014 workshop of the same name at ICRA, and discussed novel concepts and ideas for robust vision-based place recognition in severely changing environments. Organised with Peter Corke and Michael Milford.</p>

<p>Around 130 people followed the invited talks and paper presentations in a large ballroom.</p>
<div class="img_row">
<img class="col three" src="/assets/img/workshops/ICRA15Workshop.jpg" />
</div>

<hr />

<p><a href="http://www.tinyurl.com/vprice-cvpr15"><strong>Visual Place Recognition in Changing Environments</strong></a> (CVPR 2015)</p>

<p>This workshop continued the discussion from the previous year at ICRA and addressed the computer vision community at CVPR. Organised with Peter Corke and Michael Milford (QUT, Brisbane), and Torsten Sattler (ETH Zürich).</p>

<p>Approximately 40 people came by for talks and poster presentations. It was great to interact with the authors and of course the invited speakers Josef Sivic and John Leonard at CVPR as well as David Cox and Chi Hay Tong at ICRA. Thanks everybody for contributing!</p>

<hr />

<p><a href="http://www.tu-chemnitz.de/etit/proaut/ICRAWorkshopChangingEnvironments"><strong>Visual Place Recognition in Changing Environments</strong></a> (ICRA 2014)</p>

<p>Organised with Peter Corke and Michael Milford (QUT, Brisbane).
We discussed novel concepts and ideas for robust vision-based place recognition in severely changing environments. Such changes – induced e.g. by the time of day, weather or seasonal effects as well as human activity – are a ubiquitous challenge for all autonomous systems aiming at long-term operations in both indoor and outdoor settings.</p>

<p>We had 9 contributed papers, a tutorial given by Peter, and invited talks by Michael and Paul Newman.</p>

<div class="img_row_large">
<img class="col three" src="/assets/img/workshops/ICRA14Workshop.jpg" />
</div>
<div class="col three caption">
Impressions from our Workshop on Visual Place Recognition in Changing Environments at ICRA 2014. (c) Michael Milford
</div>
<hr />
<p><a href="http://www.tu-chemnitz.de/etit/proaut/ICRAWorkshopFactorGraphs"><strong>Robust and Multimodal Inference in Factor Graphs</strong></a> (ICRA 2013</p>

<p>This full-day workshop brought together researchers working on novel approaches for modelling and inference in factor graphs. The goal of the workshop was to discuss techniques that introduce a larger robustness and allow incorporating multi-modal Gaussian or non-Gaussian measurements. New concepts of how to infere multi-modal posteriors were also in the scope of the workshop, as well as novel applications beyond the ubiquitous pose graph SLAM.
I organised this workshop with John Leonard (MIT CSAIL) and Edwin Olson (University of Michigan)</p>

  </article>

  

  
    <div class="social">
  <span class="contacticon center">
    <a href="mailto:%6E%69%6B%6F.%73%75%65%6E%64%65%72%68%61%75%66@%71%75%74.%65%64%75.%61%75"><i class="fas fa-envelope"></i></a>
    
    <a href="https://scholar.google.com/citations?user=WnKjfFEAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    
    <a href="https://www.linkedin.com/in/nikosuenderhauf" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
    <a href="https://twitter.com/nikosuenderhauf" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
    
  </span>

  <div class="col three caption">
    
  </div>
</div>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2025 Niko Sünderhauf.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://nikosuenderhauf.github.io/assets/js/common.js"></script>


<!-- Load KaTeX -->
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://nikosuenderhauf.github.io/assets/js/katex.js"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>






<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://nikosuenderhauf.github.io/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-135749210-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
